.. _concept:

***************************************
Part 1. Single Agent (Deep) RL
***************************************

.. contents::
    :local:
    :depth: 3

Standard Reinforcement Learning
===================================

Reinforcement Learning is focused on goal-directed learning from interaction.
The learning entity must discover for itself which strategy produce the greatest reward by "trial and error".

Key Concepts
---------------

- **Agent**
- **Environment**
- **State**
- **Observation**
- **Action and the**
- **Transition function**
- **Reward**
- **Episode**

**Agent** represents the solution, making decisions (actions) to solve decision-making problems under uncertainty.

**Environment** is the representation of a problem which responds with the consequences of agent decisions.

**State** is a set of variables which fully describe the environment.

**Observation** is part of the state. Commonly, agent doesn't have access to the full state of the environment.

**Action** is made by the agent, influencing the environment state.

**Transition Function** is the mapping responsible for action-state chang .

**Reward** is a signal provided by the environment as a direct evaluation to the agent's actions.

**Episode** only exists when a task have a natural ending. A sequence of **timesteps** from the beginning to the end of the task forms a task episode.

Learning Cycle
-----------------

Deep Reinforcement Learning(DRL)
================================

Deep Reinforcement Learning (DRL) is the combination of Reinforcement Learning and Deep Learning.
It can solve a wide range of complex decision-making tasks that were previously out of reach for a machine to solve real-world problems with human-like intelligence.

Deep Learning(DL)
---------------------

Deep learning can learn from a training set and then applying that learning to a new data set.
Deep RL incorporates deep learning into the solution, allowing agents to make decisions from unstructured input data without manual engineering of the state space.
Deep neural networks enables RL with state representation and/or function approximation for value function, policy, and so on.

DL + RL
---------------------------


RL/DRL Algorithms
----------------------------

Model Free
^^^^^^^^^^^^

On-policy
""""""""""""

Off-policy
""""""""""""""

Model Based
^^^^^^^^^^^^

Offline RL
^^^^^^^^^^^^

Imitation RL
^^^^^^^^^^^^

Inverse RL
^^^^^^^^^^^^

Safe RL
^^^^^^^^

Etiam turis ante, luctus sed velit tristique, finibus volutpat dui. Nam sagittis vel ante nec malesuada.
Praesent dignissim mi nec ornare elementum. Nunc eu augue vel sem dignissim cursus sed et nulla.


Resources
=================


Etiam turis ante, luctus sed velit tristique, finibus volutpat dui. Nam sagittis vel ante nec malesuada.
Praesent dignissim mi nec ornare elementum. Nunc eu augue vel sem dignissim cursus sed et nulla.


