{"episode_reward_max": 10.97999999999999, "episode_reward_min": -3.090236400105084e-14, "episode_reward_mean": 5.48999999999998, "episode_len_mean": 99.5, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -1.0000000000000007}, "policy_reward_max": {"shared_policy": 10.989999999999995}, "policy_reward_mean": {"shared_policy": 2.7449999999999948}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.090236400105084e-14, 10.97999999999999], "episode_lengths": [100, 99], "policy_shared_policy_reward": [0.9999999999999845, -1.0000000000000007, 10.989999999999995, -0.009999999999999358]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1054164206627572, "mean_inference_ms": 0.5142039591723149, "mean_action_processing_ms": 0.029650064978269067, "mean_env_wait_ms": 0.07203899987853399, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 200, "timesteps_this_iter": 0, "agent_timesteps_total": 400, "timers": {"sample_time_ms": 162.171, "sample_throughput": 1233.263, "load_time_ms": 0.734, "load_throughput": 272445.859, "learn_time_ms": 48.749, "learn_throughput": 4102.651, "update_time_ms": 2.027}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 0.0005, "total_loss": 24.25593614578247, "policy_loss": -0.0004914700984954834, "vf_loss": 24.27251625061035, "vf_explained_var": 0.00021038949489593506, "kl": 2.428966925505094e-05, "entropy": 1.6094086468219757, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 200, "num_agent_steps_sampled": 400, "num_steps_trained": 200, "num_agent_steps_trained": 400}, "done": false, "episodes_total": 2, "training_iteration": 1, "trial_id": "21360_00000", "experiment_id": "31033d1de8774c65a3eb0ce72760995d", "date": "2023-05-14_20-03-56", "timestamp": 1684119836, "time_this_iter_s": 0.2015550136566162, "time_total_s": 0.2015550136566162, "pid": 43271, "hostname": "Minquans-MBP.attlocal.net", "node_ip": "127.0.0.1", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 200, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "magym", "env_args": {"step_cost": 0.01, "max_steps": 100, "map_name": "Checkers"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 2, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (47,), float64))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"Checkers": {"description": "two team cooperate", "team_prefix": ["red_", "blue_"], "all_agents_one_policy": true, "one_agent_one_policy": true}, "Switch2": {"description": "two team cooperate", "team_prefix": ["red_", "blue_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["red_0", "blue_0"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "magym_Checkers", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fdd30f7af70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 200, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.2015550136566162, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 39.5, "ram_util_percent": 93.3}}
{"episode_reward_max": 10.97999999999999, "episode_reward_min": -16.999999999999766, "episode_reward_mean": -1.0599999999999539, "episode_len_mean": 84.5, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -18.999999999999883}, "policy_reward_max": {"shared_policy": 10.989999999999995}, "policy_reward_mean": {"shared_policy": -0.5299999999999883}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.090236400105084e-14, 10.97999999999999, 1.7799999999999911, -16.999999999999766], "episode_lengths": [100, 99, 39, 100], "policy_shared_policy_reward": [0.9999999999999845, -1.0000000000000007, 10.989999999999995, -0.009999999999999358, 0.38999999999999724, 1.3900000000000003, -18.999999999999883, 2.0000000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1070418473411843, "mean_inference_ms": 0.5139514417062515, "mean_action_processing_ms": 0.029401185271669614, "mean_env_wait_ms": 0.07008963350908878, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 400, "timesteps_this_iter": 0, "agent_timesteps_total": 800, "timers": {"sample_time_ms": 203.569, "sample_throughput": 982.468, "load_time_ms": 0.457, "load_throughput": 437933.072, "learn_time_ms": 38.304, "learn_throughput": 5221.439, "update_time_ms": 2.243}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 0.0005, "total_loss": 29.96739387512207, "policy_loss": -0.0004068836569786072, "vf_loss": 29.98389196395874, "vf_explained_var": 6.22868537902832e-05, "kl": 1.3201182514972765e-05, "entropy": 1.6092703938484192, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 400, "num_agent_steps_sampled": 800, "num_steps_trained": 400, "num_agent_steps_trained": 800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4, "training_iteration": 2, "trial_id": "21360_00000", "experiment_id": "31033d1de8774c65a3eb0ce72760995d", "date": "2023-05-14_20-03-56", "timestamp": 1684119836, "time_this_iter_s": 0.1779007911682129, "time_total_s": 0.3794558048248291, "pid": 43271, "hostname": "Minquans-MBP.attlocal.net", "node_ip": "127.0.0.1", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 200, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "magym", "env_args": {"step_cost": 0.01, "max_steps": 100, "map_name": "Checkers"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 2, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (47,), float64))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"Checkers": {"description": "two team cooperate", "team_prefix": ["red_", "blue_"], "all_agents_one_policy": true, "one_agent_one_policy": true}, "Switch2": {"description": "two team cooperate", "team_prefix": ["red_", "blue_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["red_0", "blue_0"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "magym_Checkers", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fdd30f24040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 200, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.3794558048248291, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {}}
{"episode_reward_max": 10.97999999999999, "episode_reward_min": -16.999999999999766, "episode_reward_mean": 1.3228571428571683, "episode_len_mean": 80.42857142857143, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"shared_policy": -18.999999999999883}, "policy_reward_max": {"shared_policy": 10.989999999999995}, "policy_reward_mean": {"shared_policy": 0.661428571428578}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.090236400105084e-14, 10.97999999999999, 1.7799999999999911, -16.999999999999766, 10.899999999999977, -7.819999999999997, 10.420000000000012], "episode_lengths": [100, 99, 39, 100, 95, 59, 71], "policy_shared_policy_reward": [0.9999999999999845, -1.0000000000000007, 10.989999999999995, -0.009999999999999358, 0.38999999999999724, 1.3900000000000003, -18.999999999999883, 2.0000000000000004, 10.949999999999989, -0.049999999999999475, -9.409999999999997, 1.5900000000000003, 10.710000000000004, -0.28999999999999937]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.10838213523174321, "mean_inference_ms": 0.5144214063960536, "mean_action_processing_ms": 0.029277878552588094, "mean_env_wait_ms": 0.0690280723688994, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 600, "timesteps_this_iter": 0, "agent_timesteps_total": 1200, "timers": {"sample_time_ms": 199.647, "sample_throughput": 1001.771, "load_time_ms": 0.343, "load_throughput": 583487.688, "learn_time_ms": 34.082, "learn_throughput": 5868.129, "update_time_ms": 2.178}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 0.0005, "total_loss": 39.13573169708252, "policy_loss": -0.0004669390618801117, "vf_loss": 39.15228748321533, "vf_explained_var": 0.0002771914005279541, "kl": 1.1670993339540914e-05, "entropy": 1.6091048121452332, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 600, "num_agent_steps_sampled": 1200, "num_steps_trained": 600, "num_agent_steps_trained": 1200, "num_steps_trained_this_iter": 0}, "done": true, "episodes_total": 7, "training_iteration": 3, "trial_id": "21360_00000", "experiment_id": "31033d1de8774c65a3eb0ce72760995d", "date": "2023-05-14_20-03-56", "timestamp": 1684119836, "time_this_iter_s": 0.17215800285339355, "time_total_s": 0.5516138076782227, "pid": 43271, "hostname": "Minquans-MBP.attlocal.net", "node_ip": "127.0.0.1", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 100, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 200, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "magym", "env_args": {"step_cost": 0.01, "max_steps": 100, "map_name": "Checkers"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "all", "evaluation_interval": 50, "framework": "torch", "num_workers": 2, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-128"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "truncate_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (47,), float64))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 100, "policy_mapping_info": {"Checkers": {"description": "two team cooperate", "team_prefix": ["red_", "blue_"], "all_agents_one_policy": true, "one_agent_one_policy": true}, "Switch2": {"description": "two team cooperate", "team_prefix": ["red_", "blue_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["red_0", "blue_0"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "magym_Checkers", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fdd32a900d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 200, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 0.5516138076782227, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {}}
